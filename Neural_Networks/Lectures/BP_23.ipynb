{"cells":[{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699529757910,"execution_millis":5,"deepnote_to_be_reexecuted":false,"cell_id":"b761c714cc73484e9e11637acea3abb2","deepnote_cell_type":"code"},"source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom icecream import ic","block_group":"7e64b318fbfa450abe26d3edfa53ca67","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"64dd8f5d4ceb421ca9d6deb4e7cfb7ef","deepnote_cell_type":"markdown"},"source":"# Multi-Layered Neural Networks and the Backpropagation Algorithm\n\nFor easy computing potential on a neuron, the weights of incoming\nsynapses of the neuron are stored as a row vector.\n \nLet us take a neural network with the topology [2,2,1], i.e., the network\nhas 2 input neurons, 2 hidden neurons in a single hidden layer, and one\noutput neuron. Let the weights of synapses between the input and the\nhidden layer be in the following matrix:","block_group":"5f628ea15edb412a83391d153034b34d"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699529890218,"execution_millis":7,"deepnote_to_be_reexecuted":false,"cell_id":"b57b7fb0990b49d09581028308531aa6","deepnote_cell_type":"code"},"source":"w_i_h = np.array([[0.5, -0.5],\n                  [1.5,  0.5]])","block_group":"b7398ad1de01492bab536ef32076149a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"e8eb28fc68114f7880465578a3b4f5b4","deepnote_cell_type":"markdown"},"source":"`w_i_h[i,j]` is the weight of the synapse from the input `i` into the\nhidden neuron `j`. I.e., each row of the weight matrix corresponds to\nthe weights of synapses leading **from** one neuron!\n\nLet the synaptic weights between the hidden and the output layer\nbe in the matrix:","block_group":"3e12438e10d34467a5058ddfc5f5ca64"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699529906513,"execution_millis":714,"deepnote_to_be_reexecuted":false,"cell_id":"dda47bccf467486591753a1142c5398d","deepnote_cell_type":"code"},"source":"w_h_o = np.array([[2.0], [-1.0]])\nic(w_h_o)","block_group":"697b6fe593334bc6b484f9741333bea3","execution_count":null,"outputs":[{"name":"stderr","text":"ic| w_h_o: array([[ 2.],\n                  [-1.]])\n","output_type":"stream"},{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"array([[ 2.],\n       [-1.]])"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"cell_id":"8fba5cea9c7143b6bf07adb6f466570c","deepnote_cell_type":"markdown"},"source":"`w_h_o[i,0]` is the weight of the connection from the hidden neuron `i` \nto the output neuron. Thresholds of the hidden neurons are in the vector:","block_group":"6ebcd3abe58f436198fe97fc1c72bba1"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699529945498,"execution_millis":13,"deepnote_to_be_reexecuted":false,"cell_id":"13059d7d45bd47c9910b379257927f6a","deepnote_cell_type":"code"},"source":" b_h = np.array([0, 0.5])","block_group":"7bda01b709e04d4aa69dae622b647544","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"91053a70c797480eb9e0c092188a205e","deepnote_cell_type":"markdown"},"source":"and the threshold of the outout neuron is:","block_group":"47a4f42d799a4b2eb78a6fdbb7f8038d"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699530007286,"execution_millis":5,"deepnote_to_be_reexecuted":false,"cell_id":"5be32909372047afb981616779497a06","deepnote_cell_type":"code"},"source":"b_o = np.array([-0.5])","block_group":"3c0df04d8a354b47aa51945b9e95bfdb","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"fb586eae6cb7418c935ada50cf9dc4d7","deepnote_cell_type":"markdown"},"source":"Hence the weights from the input layer into the hidden layer with added \nvirtual neuron with fixed output 1 (for representing thresholds) are:","block_group":"2cdfd70ff85d424f848e0f0fbb5170ad"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699530014521,"execution_millis":6,"deepnote_to_be_reexecuted":false,"cell_id":"410124174b924c5394a394f06b0e4371","deepnote_cell_type":"code"},"source":"# note that r_ is not a method of numpy array!\nw_i_hb = np.r_[w_i_h, b_h.reshape(1,-1)]\nw_i_hb","block_group":"0f2198fa7b874ab78d64c088e327144e","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"array([[ 0.5, -0.5],\n       [ 1.5,  0.5],\n       [ 0. ,  0.5]])"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"cell_id":"f34a7e2ea6454a6493a354fa49f2be1b","deepnote_cell_type":"markdown"},"source":"The weights from the hidden layer into the output layer\nwith added virtual neuron with output 1 are:","block_group":"8decc9545fd242eda7f86c06bd94375c"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699530069230,"execution_millis":8,"deepnote_to_be_reexecuted":false,"cell_id":"7b9a0eca92b64de09e54269f2cbeec53","deepnote_cell_type":"code"},"source":"w_h_ob = np.r_[w_h_o, b_o.reshape(1,-1)]\nw_h_ob","block_group":"df5a8a50d9a94811b53ac6deb8e77787","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"array([[ 2. ],\n       [-1. ],\n       [-0.5]])"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"cell_id":"726dabf7173d45cb9445d8dd6ac42c75","deepnote_cell_type":"markdown"},"source":"A sigmoidal transfer function $$logsig(x) = \\frac{1}{1 + e^{-\\lambda x}}$$ can be implemented as","block_group":"8aab3fda64244c5bb6a316f6a807ec54"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699530100450,"execution_millis":5,"deepnote_to_be_reexecuted":false,"cell_id":"d754af2c68d3425d892128a8f69eecb1","deepnote_cell_type":"code"},"source":"def sigmoid(x, lam=1.0):\n    # sigmoid transfer function\n    #     sigmoid(x) = 1/(1 + exp{-lam * x)\n    return 1 / (1 + np.exp(-lam * x))","block_group":"33988576faab4601a72ef51a4c320a3d","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699530167393,"execution_millis":11,"deepnote_to_be_reexecuted":false,"cell_id":"3bb1c1cf0c5540a2a6b848931c4d8e4e","deepnote_cell_type":"code"},"source":"1/(1+np.exp(-3))","block_group":"f314c47345e8481dab2a5d2cdb8670dd","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"0.9525741268224334"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699530184296,"execution_millis":17,"deepnote_to_be_reexecuted":false,"cell_id":"6d123503292440f9906e8680880502c7","deepnote_cell_type":"code"},"source":"sigmoid(3)","block_group":"c1aea59fb4904f68810c777d7526485f","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0.9525741268224334"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"cell_id":"77348ec378fd4891af9d6674f83e3a11","deepnote_cell_type":"markdown"},"source":"This is the sigmoid function with the slope $\\lambda$. The default value for the slope is $\\lambda = 1$.","block_group":"c1a83399228449ab88c6045b5a5ffac7"},{"cell_type":"markdown","metadata":{"cell_id":"46674ff4a0914d62a21c43c6323c09be","deepnote_cell_type":"markdown"},"source":"## Tasks:\n\n* *Let $\\lambda=1$. Compute the output of the network for the input patterns `p1` and `p2`.*","block_group":"5fa8451dc6cd4f789839cbacf06719c1"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699530348102,"execution_millis":7,"deepnote_to_be_reexecuted":false,"cell_id":"4abe151a4dc948bc988f583f9d83e396","deepnote_cell_type":"code"},"source":"lam = 1.0\np1 = np.array([-1, 1])\np2 = np.array([ 1,-1])","block_group":"43a1acbf08f14473b2878f7b84ba08ba","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699531241802,"execution_millis":26,"deepnote_to_be_reexecuted":false,"cell_id":"18ae6aa5bc4c4dde8013829dab3bb917","deepnote_cell_type":"code"},"source":"y_o = sigmoid(np.dot(np.r_[sigmoid(np.dot(np.r_[p1, 1], w_i_hb)),1], w_h_ob))\nprint(\"y_o\\n\",y_o)","block_group":"c1160144d4344b3b8c06abe03bc5f04b","execution_count":null,"outputs":[{"name":"stdout","text":"y_o\n [0.53607289]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699531545134,"execution_millis":12,"deepnote_to_be_reexecuted":false,"cell_id":"42b65e47c97940da8749a4e1e8b1e975","deepnote_cell_type":"code"},"source":"print(sigmoid(np.r_[sigmoid(np.r_[p2, 1.] @ w_i_hb),1] @ w_h_ob))\n","block_group":"c5860471b276427a866f7b85bfdd464d","execution_count":null,"outputs":[{"name":"stdout","text":"[0.4158926]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"nbgrader":{"task":false,"grade":false,"locked":false,"checksum":"840ed81a21e35b4c0279bfbc7f4d1434","grade_id":"cell-8e13b5fce042ae6d","solution":true,"cell_type":"code","schema_version":3},"deletable":false,"source_hash":null,"execution_start":1699531661937,"execution_millis":10,"deepnote_to_be_reexecuted":false,"cell_id":"045b40f373744847a8ccefbc65685cf8","deepnote_cell_type":"code"},"source":"print(w_i_hb)\nprint(\"p1\")\n\nprint(\"p1 extended\\n\", np.r_[p1, 1])\nprint(sigmoid(np.dot(np.r_[p1, 1], w_i_hb[:,0])))    # outputs on the first hidden neuron\nprint(sigmoid(np.dot(np.r_[p1, 1], w_i_hb[:,1])))    # outputs on the second hidden neuron\n\ny_h = sigmoid(np.dot(np.r_[p1, 1], w_i_hb))     # outputs on the hidden layer\nprint(\"y_h\\n\",y_h)\ny_o = sigmoid(np.dot(np.r_[y_h,1], w_h_ob))     # output on the output layer\nprint(\"y_o\\n\",y_o)\n\nprint(\"p2\")\nprint(sigmoid(np.dot(np.r_[p2, 1], w_i_hb[:,0])))    # outputs on the hidden layer\nprint(sigmoid(np.dot(np.r_[p2, 1], w_i_hb[:,1])))    # outputs on the hidden layer\n\ny_h = sigmoid(np.dot(np.r_[p2, 1], w_i_hb))     # outputs on the hidden layer\nprint(\"y_h\\n\",y_h)\ny_o = sigmoid(np.dot(np.r_[y_h,1], w_h_ob))     # output on the output layer\nprint(\"y_o\\n\",y_o)\n\n# YOUR CODE HERE\npass","block_group":"f4b0061825cb4341b25016abeaf28443","execution_count":null,"outputs":[{"name":"stdout","text":"[[ 0.5 -0.5]\n [ 1.5  0.5]\n [ 0.   0.5]]\np1\np1 extended\n [-1  1  1]\n0.7310585786300049\n0.8175744761936437\ny_h\n [0.73105858 0.81757448]\ny_o\n [0.53607289]\np2\n0.2689414213699951\n0.3775406687981454\ny_h\n [0.26894142 0.37754067]\ny_o\n [0.4158926]\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"cell_id":"64c9c29c3a4a4cf4ba614ee3303af2d4","deepnote_cell_type":"markdown"},"source":"* *Compute the utput of the network for the whole training set `X` consisting of the patterns `p1` and `p2`.*","block_group":"abf4902dd860407ba3a2c418d4346f4d"},{"cell_type":"code","metadata":{"nbgrader":{"task":false,"grade":false,"locked":false,"checksum":"1efef519abbb01edb6d0e46f2cbdeb70","grade_id":"cell-bb2e95cf171d5dda","solution":true,"cell_type":"code","schema_version":3},"deletable":false,"source_hash":null,"execution_start":1699531935885,"execution_millis":9,"deepnote_to_be_reexecuted":false,"cell_id":"516931d42ce347fc8ee6bd35a84ad13d","deepnote_cell_type":"code"},"source":"X = np.vstack((p1, p2))\nprint(\"X\\n\", X)\nprint(np.c_[X, np.ones(X.shape[0])])\n\nX_ex = np.c_[X, np.ones(X.shape[0])]\ny_h = sigmoid(X_ex @ w_i_hb)\nprint(\"y_h\\n\", y_h)\n\ny_h_ex = np.c_[y_h, np.ones(y_h.shape[0])]\ny_o = sigmoid(y_h_ex @ w_h_ob)\nprint(\"y_o\\n\", y_o)","block_group":"043f9c04a2ee480b9600e94a1f2126ca","execution_count":null,"outputs":[{"name":"stdout","text":"X\n [[-1  1]\n [ 1 -1]]\n[[-1.  1.  1.]\n [ 1. -1.  1.]]\ny_h\n [[0.73105858 0.81757448]\n [0.26894142 0.37754067]]\ny_o\n [[0.53607289]\n [0.4158926 ]]\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"cell_id":"341d1710fa7f48f2ab88a923243e1713","deepnote_cell_type":"markdown"},"source":"The input pattern  `p1` is a training vector with the desired\noutput 0.9 and the input pattern `p2` is also a trianing pattern with the desired output 0.8. Hence the desired outputs we can store in an array, where row `d[i]` are the desired output for the pattern `X[i]`.","block_group":"d66388904b6444198f843eec03e61de1"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699532010266,"execution_millis":23,"deepnote_to_be_reexecuted":false,"cell_id":"96d4931f674d483bb283161340405e9f","deepnote_cell_type":"code"},"source":"d = np.array([[0.9],[0.8]])\nprint(\"d\\n\",d)","block_group":"cb48beba9f6b43efb5f30bf04e379082","execution_count":null,"outputs":[{"name":"stdout","text":"d\n [[0.9]\n [0.8]]\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"cell_id":"4f9a5069e1d249ed8ff193a93fc678cf","deepnote_cell_type":"markdown"},"source":"* *What is the error of the network on each of the patterns `p1` and `p2`?*","block_group":"372432104a324dfe8051c61bde6ad12e"},{"cell_type":"code","metadata":{"nbgrader":{"task":false,"grade":false,"locked":false,"checksum":"07d6fe118e151deb2c6810111448f898","grade_id":"cell-1f0991361744566c","solution":true,"cell_type":"code","schema_version":3},"deletable":false,"source_hash":null,"execution_start":1699532862061,"execution_millis":1051,"deepnote_to_be_reexecuted":false,"cell_id":"4955652d89fc423da45833c5cdc77b38","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE\n1/2 * np.sum((d[0] - y_o[0])**2)","block_group":"81fa52560ab548ee8a4882492a6cb51a","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"0.06622147161927612"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699532631090,"execution_millis":8,"deepnote_to_be_reexecuted":false,"cell_id":"c23a49a7ecbb40ab9e03bff57c66a9ca","deepnote_cell_type":"code"},"source":"1/2 * np.sum((d[1] - y_o[1])**2)","block_group":"34a0fadaae8e4266b2c8b07e9714456f","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"0.07376924828933176"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"cell_id":"c70ef9642c394ebcbfa33d4654f0f2b7","deepnote_cell_type":"markdown"},"source":"* *What is the mean squared error (MSE) of the network on the whole training set?*","block_group":"db07f388be5a45e7919a54e25a087eb7"},{"cell_type":"code","metadata":{"nbgrader":{"task":false,"grade":false,"locked":false,"checksum":"ec34642b43c47a1daa3c6fd8bec1b2ff","grade_id":"cell-65f7a5b84e447a29","solution":true,"cell_type":"code","schema_version":3},"deletable":false,"source_hash":null,"execution_start":1699532713433,"execution_millis":136,"deepnote_to_be_reexecuted":false,"cell_id":"da236e24d01f43a9964b0a150b2d8e3c","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE\nic(1/2*np.sum((d-y_o)**2, axis=1))\nnp.mean(1/2*np.sum((d-y_o)**2, axis=1))","block_group":"ca3c7a0bd97846ba8622f85ebc2bfc07","execution_count":null,"outputs":[{"name":"stderr","text":"ic| 1/2*np.sum((d-y_o)**2, axis=1): array([0.06622147, 0.07376925])\n","output_type":"stream"},{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"0.06999535995430395"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"cell_id":"626a061bdd324613a3d07bcb9d9e22a5","deepnote_cell_type":"markdown"},"source":"* *How will change the weights of the network after one step of the\n  backpropagation learning algorithm (without momentum) with the training pattern `p1`\n  with the learning rate $\\alpha = 0.2$?*","block_group":"698367faf8ee4664a52d37d329e48f79"},{"cell_type":"code","metadata":{"cell_id":"7cf543579e044920b954b4bb15f8de9c","deepnote_cell_type":"code"},"source":"alpha = 0.2","block_group":"793d3a2aa76044749998c4476df99b2a","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"aa16a85c224d451fa0c7fe160a35a963","deepnote_cell_type":"markdown"},"source":"The error terms at neuron $j$ in the output layer\n\n$$\\hspace{4em} \\displaystyle \\delta_j = (d_j-y_j)\\cdot \\lambda  y_j (1 - y_j)$$","block_group":"6d542385a213442caa5ae41ab60840ca"},{"cell_type":"code","metadata":{"nbgrader":{"task":false,"grade":false,"locked":false,"checksum":"fea4537c89abbe6d9b13ad91fd4aa6af","grade_id":"cell-8e8822205f851ff","solution":true,"cell_type":"code","schema_version":3},"deletable":false,"source_hash":null,"execution_start":1699533389410,"execution_millis":6,"deepnote_to_be_reexecuted":false,"cell_id":"2bde4877d6ed498fbac6cd3fdc88e1df","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE\ny_h = sigmoid(np.c_[X, np.ones(X.shape[0])] @ w_i_hb)\ny_o = sigmoid(np.c_[y_h, np.ones(X.shape[0])] @ w_h_ob)\n\ndelta_o = (d - y_o) * lam * y_o * (1. - y_o)\nprint(delta_o[0])","block_group":"b84f1d0f34fe46a285cdc00fa03f9a9c","execution_count":null,"outputs":[{"name":"stdout","text":"[0.09050822]\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"cell_id":"07c9b609c6354675996762763b9d9db6","deepnote_cell_type":"markdown"},"source":"The error term at neuron $j$ in a hidden layer\n$$\\hspace{4em} \\displaystyle \\delta_j = \\big(\\sum_k \\delta_k w_{jk}\\big) \\cdot \\lambda y_j (1 - y_j)$$","block_group":"d9297a5cab1f4e6d84a87d3f4da1d1f3"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699534246268,"execution_millis":16,"deepnote_to_be_reexecuted":false,"cell_id":"8dd5ed6e32b149bebb0e1204141990e4","deepnote_cell_type":"code"},"source":"delta_o","block_group":"64b315ac646d485c94be9c0c70010bdd","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"array([[0.09050822],\n       [0.09330965]])"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699534290381,"execution_millis":412,"deepnote_to_be_reexecuted":false,"cell_id":"3480fb4302a842b6a7b2c0b02328e157","deepnote_cell_type":"code"},"source":"ic((delta_o[0] * w_h_ob))","block_group":"eebddaf3d3ac49c983aefe6f4ce2b2dd","execution_count":null,"outputs":[{"name":"stderr","text":"ic| delta_o[0] * w_h_ob: array([[ 0.18101643],\n                                [-0.09050822],\n                                [-0.04525411]])\n","output_type":"stream"},{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"array([[ 0.18101643],\n       [-0.09050822],\n       [-0.04525411]])"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699534469220,"execution_millis":11,"deepnote_to_be_reexecuted":false,"cell_id":"b85497fa07c34879912bd3d323321c0e","deepnote_cell_type":"code"},"source":"y_h","block_group":"5cf1fa22420e4eaeb742c42e2e041efa","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"array([[0.73105858, 0.81757448],\n       [0.26894142, 0.37754067]])"},"metadata":{}}]},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1699534566456,"execution_millis":17,"deepnote_to_be_reexecuted":false,"cell_id":"43637131f55e42588bbb8fcb8b69a9a6","deepnote_cell_type":"code"},"source":"y_h_ex = np.c_[y_h, np.ones(y_h.shape[0])]\ny_h_ex","block_group":"1d31e659c2c5491690a157230ab100b2","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"array([[0.73105858, 0.81757448, 1.        ],\n       [0.26894142, 0.37754067, 1.        ]])"},"metadata":{}}]},{"cell_type":"code","metadata":{"nbgrader":{"task":false,"grade":false,"locked":false,"checksum":"002f87fdfc7763f678cda72b8450e4a0","grade_id":"cell-8e8822205f851ffa","solution":true,"cell_type":"code","schema_version":3},"deletable":false,"source_hash":null,"execution_start":1699534650679,"execution_millis":10,"deepnote_to_be_reexecuted":false,"cell_id":"d20a9b9525a24063b9fac34c1afc9c31","deepnote_cell_type":"code"},"source":"delta_h = (delta_o[0] * w_h_ob) * lam * y_h_ex[0].reshape(-1,1) * (1 - y_h_ex[0].reshape(-1,1))            # delta terms at the hidden layer\nprint(delta_h)\n\nw_h_ob1 = ...               # new weights from the hidden to the output layer\nw_i_hb1 = ...               # new weights form the input to the output layer\n# YOUR CODE HERE\n","block_group":"f80741c370474d88a8761d83e3c7917e","execution_count":null,"outputs":[{"name":"stdout","text":"[[ 0.03558999]\n [-0.01349898]\n [-0.        ]]\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"cell_id":"9d29e0efd13b49009ee9016cc50c83a5","deepnote_cell_type":"markdown"},"source":"   \n* How will change the output of the network for input `p1` after the first \n  iteration of the backpropagation algorithm?*","block_group":"f5c5b94dc8874a05b467c6b6e87ad605"},{"cell_type":"code","metadata":{"nbgrader":{"task":false,"grade":false,"locked":false,"checksum":"cf2354dbeb9d86ad50e57152cf5116a4","grade_id":"cell-10833e3745521393","solution":true,"cell_type":"code","schema_version":3},"deletable":false,"cell_id":"2d87f4e7c5584498902bd342c4f099a0","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE\nraise NotImplementedError()","block_group":"2a56bea2e0454bee92a0d2966d2f1b97","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"51be240955e74e0799b1a49a171ebe98","deepnote_cell_type":"markdown"},"source":"* *Estimate the number of iterations over the pattern `p1` necessary to obtain an error \"close\" to 0*","block_group":"4b50d11e707840e18a75b62fabd7284f"},{"cell_type":"code","metadata":{"cell_id":"0c7553c2070046c4b6b25a713b0a6bf6","deepnote_cell_type":"code"},"source":"alpha = 0.2\nlam = 1.0\n\n","block_group":"d33b6030b5834ba7857704c9b8b8b0e6","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"674d71f862ee416c9636b827ac607312","deepnote_cell_type":"markdown"},"source":"**Notation:**\n\nUsing `numpy` for working with vectors and matrices when we train a neural network has some problems:\n* Input: input patterns are stored as rows in a 2D matrix $X$, but one input pattern is a 1D vector.\n* Output, desired output: output patterns are stored as rows in a 2D matrix $Y$, however one output pattern is a 1D vector.\n* Output of hidden neurons: can be stored in rows of a 2D matrix if we compute output for more than one pattern, but it is a 1D vector if we compute with one input vector.\n\nA possible solution: is to *store vectors as two-dimensional arrays*:\n* Then we can distinguish row and column vectors.\n* If we work with a single vector, we will convert it into a row vector.","block_group":"dcf640cf41bf42fbace4ac47e804a270"},{"cell_type":"code","metadata":{"cell_id":"343f6d5ecc3045af914d1934caa9410b","deepnote_cell_type":"code"},"source":"p1_2d = p1.reshape(1,-1)\nprint(\"p1_2d\\n\",p1_2d)","block_group":"32729986522e46919db8684e3ef77a2f","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"ba6f0a949abf475d8ed4482a91474cf5","deepnote_cell_type":"code"},"source":"# output of the hidden neurons\ny_h = ...\nprint(\"y_h\\n\", y_h)","block_group":"985a7db465fd4713b57bc533b16b05c8","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"e15f18dd26c746beb928bd8a0aecf98c","deepnote_cell_type":"code"},"source":"# output of the network \ny_o = ...\nprint(\"y_o\\n\", y_o)","block_group":"6e7147e8d84a43a2b05c663e1da4b072","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"3ac16c8f78274fce986ba2580a126b7d","deepnote_cell_type":"code"},"source":"delta_o = ...\nprint(\"delta_o\\n\", delta_o)","block_group":"e54cdfd754cb429984dfce7b13784b4d","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"619626209b7148c59e628367aa93feeb","deepnote_cell_type":"markdown"},"source":"Note that `delta_o` **is a row vector**? Why?","block_group":"38663290f7e6458983bf9f942e5fdf13"},{"cell_type":"code","metadata":{"cell_id":"554e24b94a8f41358175595479d8bb64","deepnote_cell_type":"code"},"source":"print(\"np.c_[y_h,[[1]]]\\n\", np.c_[y_h,[[1]]])\n\nw_h_ob1 = w_h_ob + ...\nprint(\"w_h_ob1\\n\", w_h_ob1)","block_group":"cbd496991ac043d097c45f2068bfe298","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"f3ffb07a83ff40ce91aa24cf330a44fe","deepnote_cell_type":"code"},"source":"delta_h = ...\nprint(\"delta_h\\n\", delta_h)","block_group":"4fc1cac1854c49ffb0009755daaff541","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"722fa854ab514cd0bced60cdac5f3643","deepnote_cell_type":"code"},"source":"\nw_i_hb1 = ...\nprint(\"w_i_hb1\\n\", w_i_hb1)","block_group":"f71a2674b0ec44119aa6dd3a6611c0c1","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"a5e0a8cb42f14a3d8b951ea689c1ecbf","deepnote_cell_type":"markdown"},"source":"Now for the second pattern `p2`.","block_group":"9a3d3846475d49e18c0b94c679cc027d"},{"cell_type":"code","metadata":{"cell_id":"97a94eaad5bb48228bbddb81d0df73cd","deepnote_cell_type":"code"},"source":"p2_2d = p2.reshape(1,-1)\nprint(\"p2_2d\\n\",p2_2d)","block_group":"1937364d01174b8ca96b9391acbf9bc4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"948ac135943f47a4a06ea229fee91403","deepnote_cell_type":"code"},"source":"# output of the hidden neurons\n\ny_h = ...\nprint(\"y_h\\n\", y_h)","block_group":"497fee5e61ba473f85802407460d335a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"e5dcdc6ce067470caab2c30b87c12d22","deepnote_cell_type":"code"},"source":"y_o = ...\nprint(\"y_o\\n\", y_o)","block_group":"1408ad942df0400bac868cbe3f79a6f9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"5afe876a642d4a7c8750b7229abe903d","deepnote_cell_type":"code"},"source":"\ndelta_o = ...\nprint(\"delta_o\\n\", delta_o)","block_group":"3c9efc897b714bf09cf93091c27cdde3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"180954d6d4464d798c749299e2622aa5","deepnote_cell_type":"code"},"source":"w_h_ob1 = ...\nprint(\"w_h_ob1\\n\", w_h_ob1)","block_group":"f417c021f2194e3784bf78601c0090ab","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"b24af50962524dd988c9383bd61b8a7f","deepnote_cell_type":"code"},"source":"delta_h = ...\nprint(\"delta_h\\n\", delta_h)","block_group":"23e93f8a1e0a4202881c3d77d36df30c","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"b8e171f6dc304c80961e657dc6649bea","deepnote_cell_type":"code"},"source":"w_i_hb1 = ... \nprint(\"w_i_hb1\\n\", w_i_hb1)","block_group":"8752b478225b481b84381046fc7a5818","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"764e77f35ef34901857bfed0cbbb62be","deepnote_cell_type":"code"},"source":"","block_group":"7c77e77423c04abe81ee34ac2009061c","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=61b28771-206e-4d0b-8437-9015c75dcd39' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python","version":"3.9.16","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"337f78587e8a4608ba3bb762b5338c7e","deepnote_persisted_session":{"createdAt":"2023-11-09T13:17:25.215Z"},"deepnote_execution_queue":[]}}