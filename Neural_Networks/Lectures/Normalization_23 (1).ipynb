{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "37b06f2d55f54e85af3f3b03dd724973",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Data Normalization\n",
    "\n",
    "We have some source data as a vector of real values $x = (x_0, x_2,\\dots, x_{n-1}) \\in \\mathbb{R}^n$. Normalization of $X$ is a function $f: \\mathbb{R}^n \\to \\mathbb{R}^n$ that maps the data into a suitable range while preserving relations between the components. E.g., if $f(x) = (y_0, y_1,\\ldots,y_{n-1})$ and if $x_i \\ge x_j$, for some integers $i$, $j$ between $0$ and $n-1$, then it should hold $y_i \\ge y_j$.\n",
    "\n",
    "## Min-max normalization onto an interval $\\langle A,B \\rangle$\n",
    "\n",
    "Implement a function `mmnormalize_list(x, A=0, B=1)` that maps an arbitrary input vector `x`, represented as a **list** of floats, linearly onto the interval $\\langle A,B \\rangle$. Usually, we use min-max normalization onto the interval $\\langle 0, 1 \\rangle$ or $\\langle -1, 1 \\rangle$. For example\n",
    "\n",
    "    >>> mmnormalize_list([0.12, 3, -123],-1,1)\n",
    "    [0.9542857142857144, 1.0, -1.0]\n",
    "    \n",
    "    >>> mmnormalize_list([0.12, 3, -123],0,1)\n",
    "    [0.9771428571428572, 1.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "6908d4c1eb664d0da972261d1f872547",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2054,
    "execution_start": 1696967328893,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "4747736c53b24a7b85170760500a5060",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Min-max normalization on a list and a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "030f8c409bba41e09eb92e442a58350d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 31,
    "execution_start": 1696967331892,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9542857142857144, 1.0, -1.0]\n",
      "[0.0, 0.2, 0.26666666666666666, 0.3333333333333333, 1.0]\n"
     ]
    }
   ],
   "source": [
    "def mmnormalize_list(x, A=0, B=1):\n",
    "    # x is a list of floats\n",
    "    # returns a list with values maped linearly into the interval <A,B>\n",
    "    # your code goes here\n",
    "    minv = min(x)\n",
    "    maxv = max(x)\n",
    "    return [(v - minv) / (maxv - minv) * (B - A) + A for v in x]\n",
    "\n",
    "print(mmnormalize_list([0.12, 3, -123],-1,1))\n",
    "print(mmnormalize_list([-5,-2,-1,0,10],0,1))\n",
    "assert(np.allclose(mmnormalize_list([-5,-2,-1,0,10],0,1), [0.0, 0.2, 0.26666666666666666, 0.3333333333333333, 1.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2bcfc1a44df54925ba4277ee00929253",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Using `matplotlib`, depict in a single plot `x` and `mmnormalize_list(x,A,B)` â€“- e.g., with `x` on the horizontal axis and `mmnormalize_list(x,A,B)` on the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "b75a2b7f57cf4c91a6eecf9fb07c7aa2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 205,
    "execution_start": 1696967334542,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [-5,-2,-1,0,10]\n",
    "# your code goes here\n",
    "y = mmnormalize_list(x)\n",
    "plt.scatter(x, y)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "84b6de2d33ca43a5897d138ecd685251",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Implement another version of min-max normalization `mmnormalize` that accepts input data represented as a **two-dimensional numpy array**. Each row of the two-dimensional input array `X` is one observation. A column of `X` is the value of an attribute for all observations. Therefore, the normalization is performed **column-wise**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "6e14c154d13c4222a4b000b8c92fc17d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25,
    "execution_start": 1696967336986,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.20e-01  2.00e+00]\n",
      " [ 3.00e+00  5.00e+00]\n",
      " [-1.23e+02  7.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.12, 2], [3, 5], [-123, 7]])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "10fe44aa4cc04648a730343b12b7e1cb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 31,
    "execution_start": 1696967339733,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.77142857,  0.        ],\n",
       "       [10.        ,  6.        ],\n",
       "       [ 0.        , 10.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "def mmnormalize(X, A=0, B=1):\n",
    "    # X is a two-dimensional numpy array of floats\n",
    "    # returns a numpy array with values from X maped linearly into the interval <A,B>\n",
    "    # your code goes her\n",
    "    with warnings.catch_warnings():\n",
    "     warnings.simplefilter(\"error\")\n",
    "\n",
    "     max_data = np.max(X, axis=0)\n",
    "     mim_data = np.min(X, axis=0)\n",
    "   \n",
    "     try:\n",
    "         return (B-A) * ((X - mim_data)/(max_data-mim_data))+A\n",
    "     except RuntimeWarning:\n",
    "         return X\n",
    "    \n",
    "mmnormalize(X, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "10fe44aa4cc04648a730343b12b7e1cb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 31,
    "execution_start": 1696967339733,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.77142857,  0.        ],\n",
       "       [10.        ,  6.        ],\n",
       "       [ 0.        , 10.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "def mmnormalize(X, A=0, B=1):\n",
    "    # X is a two-dimensional numpy array of floats\n",
    "    # returns a numpy array with values from X maped linearly into the interval <A,B>\n",
    "    # your code goes here\n",
    "    normalize = lambda arr: mmnormalize_list(arr, A, B)\n",
    "    return np.apply_along_axis(normalize, 0, X)\n",
    "    \n",
    "mmnormalize(X, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "10fe44aa4cc04648a730343b12b7e1cb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 31,
    "execution_start": 1696967339733,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.77142857,  0.        ],\n",
       "       [10.        ,  6.        ],\n",
       "       [ 0.        , 10.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "def mmnormalize(X, A=0, B=1):\n",
    "    # X is a two-dimensional numpy array of floats\n",
    "    # returns a numpy array with values from X maped linearly into the interval <A,B>\n",
    "    # your code goes here\n",
    "\n",
    "    MIN = np.min(X,axis=0)\n",
    "    MAX = np.max(X,axis=0)\n",
    "    return (B-A) * ((X - MIN)/(MAX-MIN))+A\n",
    "    \n",
    "mmnormalize(X, 0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e42ebe7c6f4541208f0ced916ff5cab5",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Are there special cases that should be considered when implementing/using the above functions?\n",
    "\n",
    "What should be the output of the following statement?\n",
    "\n",
    "Answer during class: When maximum and minmimum given are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "36bfc338e65540e1a2b16a37e5926651",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 25,
    "execution_start": 1696967344652,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmnormalize(np.ones((3,1)), 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d85fd454b82e49f9be22e455272775f3",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Make sure that the previous statement runs correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e793cc6ed56a4639a90aec18273cbbd8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Class `MmNormalizer`\n",
    "However, we also must be able \n",
    "1. to apply the same transformation to new data, and\n",
    "2. to compute the inverse transformation. \n",
    "Implement another version of `mmnormalize` as a class `MmNormalizer` that can not only compute the min-max normalization but stores also the parameters of the transformation. This enables the application of the same normalization on new data or to compute the inverse transformation.\n",
    "\n",
    "Such class should implement the following methods:\n",
    "* `fit_transform(self, X)`: fit normalization to data X;\n",
    "* `apply(self, X)`: apply normalization to data X using parameters \n",
    "  of the transformation stored in the object;\n",
    "* `inverse(self, X)`: apply the inverse transformation of the normalization to data X \n",
    "  using parameters of the transformation stored in the object.\n",
    "\n",
    "Let us define an abstract class `Normalizer`, which will serve as a base class for any normalizer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "e66c2cffdc1b4c3f90ee3f0bdeeab666",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 36,
    "execution_start": 1696967349012,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Normalizer:\n",
    "    \"\"\"A base class for normalization\"\"\"\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit normalizer to data X;\n",
    "        the method returns transformed data, \n",
    "        and saves parameters of the transformation in internal attributes.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "                                \n",
    "    def apply(self, X):\n",
    "        \"\"\"Apply normalization to data X using parameters \n",
    "        of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "                        \n",
    "    def inverse(self, X):\n",
    "        \"\"\"Apply the inverse transformation of the normalization to data X \n",
    "        using parameters of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7047fd515a8f418daa365a392a1b66c8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Now we can define a class `MmNormalizer` that will implement min-max normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "d22a46859f8948dc80564fb5dd294ae1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1696967354475,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "class MmNormalizer(Normalizer):\n",
    "    \"\"\"A class for min-max normalization\"\"\"\n",
    "    \n",
    "    def __init__(self, A=0, B=1):\n",
    "        \"\"\"Constructor for min-max normalizer into the interval <A,B>\"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit min-max normalizer to data X, constant features (columns) \n",
    "        are mapped into the middle of the interval <A,B>;\n",
    "        the method returns transformed data, \n",
    "        and saves parameters of the transformation in internal attributes.\n",
    "        \"\"\"\n",
    "        self.max_data = np.max(X, axis=0)\n",
    "        self.min_data = np.min(X, axis=0)\n",
    "        #float\n",
    "        #Better take 0.5\n",
    "        constants = int(self.B - ((self.B - self.A)/2))\n",
    "        normalized =  (self.B-self.A) * ((X - self.min_data)/(self.max_data-self.min_data))+self.A\n",
    "        return np.nan_to_num(x=normalized , nan=(constants))\n",
    "                                \n",
    "    def apply(self, X):\n",
    "        \"\"\"Apply min-max normalization to data X using parameters \n",
    "        of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        constants = int(self.B - ((self.B - self.A)/2))\n",
    "        \n",
    "        normalized =  (self.B-self.A) * ((X - self.min_data)/(self.max_data-self.min_data))+self.A\n",
    "        return np.nan_to_num(x=normalized , nan=(constants).astype('int'))\n",
    "                        \n",
    "    def inverse(self, X):\n",
    "        \"\"\"Apply the inverse transformation of min-max normalization to data X \n",
    "        using parameters of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        # Did not add the 'constant' part to it\n",
    "        return (X - self.A) * ((self.max_data - self.min_data) / (self.B - self.A)) + self.min_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "d22a46859f8948dc80564fb5dd294ae1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1696967354475,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "class MmNormalizer(Normalizer):\n",
    "    \"\"\"A class for min-max normalization\"\"\"\n",
    "    \n",
    "    def __init__(self, A=0, B=1):\n",
    "        \"\"\"Constructor for min-max normalizer into the interval <A,B>\"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "    def fit_transform(self, X: np.ndarray):\n",
    "        \"\"\"Fit min-max normalizer to data X, constant features (columns) \n",
    "        are mapped into the middle of the interval <A,B>;\n",
    "        the method returns transformed data, \n",
    "        and saves parameters of the transformation in internal attributes.\n",
    "        \"\"\"\n",
    "        self.minv = X.min(axis=0)\n",
    "        self.maxv = X.max(axis=0)\n",
    "        return np.nan_to_num((X - self.minv) / (self.maxv - self.minv), False, 0.5) * (self.B - self.A) + self.A\n",
    "                                \n",
    "    def apply(self, X: np.ndarray):\n",
    "        \"\"\"Apply min-max normalization to data X using parameters \n",
    "        of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        return np.nan_to_num((X - self.minv) / (self.maxv - self.minv), False, 0.5) * (self.B - self.A) + self.A\n",
    "        pass\n",
    "                        \n",
    "    def inverse(self, X: np.ndarray):\n",
    "        \"\"\"Apply the inverse transformation of min-max normalization to data X \n",
    "        using parameters of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        return np.nan_to_num((X - self.A) / (self.B - self.A), False, 0.5) * (self.maxv - self.minv) + self.minv\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "d22a46859f8948dc80564fb5dd294ae1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 11,
    "execution_start": 1696967354475,
    "jupyter": {
     "source_hidden": true
    },
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "class MmNormalizer2(Normalizer):\n",
    "    \"\"\"A class for min-max normalization\"\"\"\n",
    "    \n",
    "    def __init__(self, A=0, B=1):\n",
    "        \"\"\"Constructor for min-max normalizer into the interval <A,B>\"\"\"\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit min-max normalizer to data X, constant features (columns) \n",
    "        are mapped into the middle of the interval <A,B>;\n",
    "        the method returns transformed data, \n",
    "        and saves parameters of the transformation in internal attributes.\n",
    "        \"\"\"\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"error\")\n",
    "\n",
    "            self.max_data = np.max(X, axis=0)\n",
    "            self.min_data = np.min(X, axis=0)\n",
    "\n",
    "            try:\n",
    "                print(\"test\")\n",
    "                for v in X:\n",
    "                    print(v)\n",
    "                return (self.B-self.A) * ((X - self.min_data)/(self.max_data-self.min_data))+self.A\n",
    "            except RuntimeWarning:\n",
    "                #sys.stdout.write(\"RunTimeWarning\")\n",
    "                np.seterr(divide='ignore', invalid='ignore')\n",
    "                print(\"test\")\n",
    "                for v in X:\n",
    "                    print(v)\n",
    "                return (self.B-self.A) * ((X - self.min_data)/(self.max_data-self.min_data))+self.A\n",
    "                #return X\n",
    "                                \n",
    "    def apply(self, X):\n",
    "        \"\"\"Apply min-max normalization to data X using parameters \n",
    "        of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        return (self.B-self.A) * ((X - self.min_data)/(self.max_data-self.min_data))+self.A\n",
    "                        \n",
    "    def inverse(self, X):\n",
    "        \"\"\"Apply the inverse transformation of min-max normalization to data X \n",
    "        using parameters of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        return (X - self.A) * ((self.max_data - self.min_data) / (self.B - self.A)) + self.min_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "7eb4903659b04a9b8ff43ea2adec4105",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 23,
    "execution_start": 1696967357196,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.20e-01  2.00e+00]\n",
      " [ 3.00e+00  5.00e+00]\n",
      " [-1.23e+02  7.00e+00]]\n",
      "[[ 9.77142857  0.        ]\n",
      " [10.          6.        ]\n",
      " [ 0.         10.        ]]\n",
      "[[ 1.20e-01  2.00e+00]\n",
      " [ 3.00e+00  5.00e+00]\n",
      " [-1.23e+02  7.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.12, 2], [3, 5], [-123, 7]])\n",
    "print(X)\n",
    "mmn = MmNormalizer(0,10)\n",
    "X_norm = mmn.fit_transform(X)\n",
    "print(X_norm)\n",
    "assert(np.allclose(X_norm, np.array([[9.77142857, 0], [10, 6], [0, 10]])))\n",
    "print(mmn.inverse(X_norm))\n",
    "assert(np.allclose(mmn.inverse(X_norm), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "83f9da5f281a403aa00d89702c8212f5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 54,
    "execution_start": 1696967360067,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.  5.  0.]\n",
      " [ 5.  5.  5.]\n",
      " [ 5.  5. 10.]]\n",
      "[[1. 3. 0.]\n",
      " [1. 3. 1.]\n",
      " [1. 3. 2.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yjara\\AppData\\Local\\Temp\\ipykernel_17268\\1443785634.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized =  (self.B-self.A) * ((X - self.min_data)/(self.max_data-self.min_data))+self.A\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack((np.ones((3,1)), 3*np.ones((3,1)),np.arange(3).reshape((3,1))))\n",
    "\n",
    "#print(X)\n",
    "mmn = MmNormalizer(0,10)\n",
    "X_norm = mmn.fit_transform(X)\n",
    "print(X_norm)\n",
    "\n",
    "assert(np.allclose(X_norm, np.array([[5, 5, 0], [5, 5, 5], [5, 5, 10]])))\n",
    "print(mmn.inverse(X_norm))\n",
    "assert(np.allclose(mmn.inverse(X_norm), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "9b7ceabb74b04ce48c4418b0770d6805",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 813,
    "execution_start": 1696967364023,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 3. 0.]\n",
      " [1. 3. 1.]\n",
      " [1. 3. 2.]]\n",
      "[[-20. -20. -20.]\n",
      " [-20. -20.  -5.]\n",
      " [-20. -20.  10.]]\n",
      "[[1. 3. 0.]\n",
      " [1. 3. 1.]\n",
      " [1. 3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = np.hstack((np.ones((3,1)), 3*np.ones((3,1)),np.arange(3).reshape((3,1))))\n",
    "print(X)\n",
    "mm = MinMaxScaler(feature_range=(-20,10))\n",
    "Xt = mm.fit_transform(X)\n",
    "print(Xt)\n",
    "Xback = mm.inverse_transform(Xt)\n",
    "print(Xback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "263aee32b93c448585ec8943025cd9e3",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Normalization by the standard deviation\n",
    "\n",
    "\n",
    "*Population standard deviation* measures the spread of a data distribution. It measures the typical distance between each data point and the mean. The *sample standard deviation* is an unbiased estimate of the population standard deviation. The sample standard deviation is defined as\n",
    "$$sd(X)= \\sigma_X=\\sqrt{\\frac{\\sum(X-\\bar{X})^2}{N-1}},$$\n",
    "where $\\bar{X}=\\frac{1}{N} \\cdot \\sum_{i=1}^{N} x_i$ is the mean value of $X$.\n",
    "\n",
    "Normalization by the standard deviation transforms an input vector linearly so that the mapped data will have the mean 0 and the (sample) standard deviation 1.\n",
    "\n",
    "Implement the methods of the following class `SdNormalizer` that should implement normalization by standard deviation. Its method `fit_transform(X)` transforms two-dimensional array `X` linearly into an array with the mean 0 and the (sample) standard deviation 1 in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "9c11d57ba5414c36983f68e49cbfd6ea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1696968312892,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "class SdNormalizer(Normalizer):\n",
    "    \"\"\"A class for normalization by the standard deviation\"\"\"\n",
    "            \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit SdNormalizer to data X, constant features (columns) \n",
    "        are mapped into 0 (not satisfying the requirements that \n",
    "        the standard deviation is 1);\n",
    "        the method returns transformed data, \n",
    "        and saves parameters of the transformation in internal attributes.\n",
    "        \"\"\"\n",
    "        #Mean and standard deviation\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.std = np.std(X, axis=0) \n",
    "        #ddof=1 is storing the standard deviation\n",
    "        #ddof=1 less biased, so this is the -1\n",
    "\n",
    "        # Normalize\n",
    "        self.normalized = X - self.mean\n",
    "\n",
    "        # In case standard deviation is 0\n",
    "        #self.std[self.std == 1] = 0\n",
    "\n",
    "        # Set constant features (columns) standard deviation to 1\n",
    "        constant = np.where(self.std == 0)[0]\n",
    "        self.std[constant] = 1\n",
    "\n",
    "        # Scale within one standard deviation\n",
    "        self.normalized = self.normalized / self.std\n",
    "        return self.normalized\n",
    "\n",
    "    def apply(self, X):\n",
    "        \"\"\"apply the normalization by the standard deviation to data X using parameters \n",
    "        of the transformation stored in the object\n",
    "        \"\"\"\n",
    "        # Normalize\n",
    "        self.normalized = X - self.mean\n",
    "\n",
    "        # In case standard deviation is 0\n",
    "        #self.std[self.std == 1] = 0\n",
    "\n",
    "        # Set constant features (columns) standard deviation to 1\n",
    "        constant = np.where(self.std == 0)[0]\n",
    "        self.std[constant] = 1\n",
    "\n",
    "        # Scale within one standard deviation\n",
    "        self.normalized = self.normalized / self.std\n",
    "        return self.normalized\n",
    "                        \n",
    "    def inverse(self, X):\n",
    "        \"\"\"apply the inverse transformation of the normalization by the standard deviation to data X \n",
    "        using parameters of the transformation stored in the object\n",
    "        \"\"\"\n",
    "        # Inverse\n",
    "        inverse_data = (X * self.std) + self.mean\n",
    "        return inverse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "9c11d57ba5414c36983f68e49cbfd6ea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1696968312892,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "class SdNormalizer(Normalizer):\n",
    "    \"\"\"A class for normalization by the standard deviation\"\"\"\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit SdNormalizer to data X, constant features (columns)\n",
    "        are mapped into 0 (not satisfying the requirements that\n",
    "        the standard deviation is 1);\n",
    "        the method returns transformed data,\n",
    "        and saves parameters of the transformation in internal attributes.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        self.mean = X.mean(axis=0)\n",
    "        self.stddev = X.std(axis=0, ddof=1)  \n",
    "        \n",
    "        # standard deviation is zero for constant features\n",
    "        self.stddev[self.stddev == 0] = 1.0\n",
    "        \n",
    "        return self.apply(X)\n",
    "\n",
    "    def apply(self, X):\n",
    "        \"\"\"apply the normalization by the standard deviation to data X using parameters\n",
    "        of the transformation stored in the object\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        normalized_X = (X - self.mean) / self.stddev\n",
    "        return normalized_X\n",
    "\n",
    "    def inverse(self, X):\n",
    "        \"\"\"apply the inverse transformation of the normalization by the standard deviation to data X\n",
    "        using parameters of the transformation stored in the object\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        original_X = X * self.stddev + self.mean\n",
    "        return original_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class SdNormalizer2(Normalizer):\n",
    "    \"\"\"A class for normalization by the standard deviation\"\"\"\n",
    "            \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit SdNormalizer to data X, constant features (columns) \n",
    "        are mapped into 0 (not satisfying the requirements that \n",
    "        the standard deviation is 1);\n",
    "        the method returns transformed data, \n",
    "        and saves parameters of the transformation in internal attributes.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "\n",
    "        #Mean and standard deviation\n",
    "        #self.mean = X.mean(axis=0) \n",
    "        #self.std = X.std(axis=0)\n",
    "\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.std = np.std(X, axis=0)\n",
    "\n",
    "        # Normalize\n",
    "        self.normalized = X - self.mean\n",
    "\n",
    "        # In case standard deviation is 0\n",
    "        self.std[self.std == 1] = 0\n",
    "\n",
    "        # Scale within one standard deviation\n",
    "        self.normalized = self.normalized / self.std\n",
    "\n",
    "        # Normalize by substracting mean and deviding by standard deviation\n",
    "        #self.normalized = (X - self.mean) / self.std\n",
    "        return self.normalized\n",
    "\n",
    "\n",
    "    def fit_transform2(self, X):\n",
    "        \"\"\"Fit SdNormalizer to data X, constant features (columns) \n",
    "        are mapped into 0 (not satisfying the requirements that \n",
    "        the standard deviation is 1);\n",
    "        the method returns transformed data, \n",
    "        and saves parameters of the transformation in internal attributes.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        num_rows = len(X)\n",
    "        num_cols = len(X[0])\n",
    "\n",
    "        # Calculate the mean and standard deviation for each column\n",
    "        self.mean = [sum(X[i][j] for i in range(num_rows)) / num_rows for j in range(num_cols)]\n",
    "        self.std = [(sum((X[i][j] - self.mean[j]) ** 2 for i in range(num_rows)) / (num_rows - 1)) ** 0.5 for j in range(num_cols)]\n",
    "\n",
    "        # Transform the data by subtracting the mean and dividing by the standard deviation\n",
    "        X_normalized = [[(X[i][j] - self.mean[j]) / self.std[j] for j in range(num_cols)] for i in range(num_rows)]\n",
    "        return np.array(X_normalized)\n",
    "        #return X_normalized\n",
    "\n",
    "       # normalized_data_within_one_std = [max(min(x, 1), -1) for x in self.normalized]\n",
    "       # print(normalized_data_within_one_std)\n",
    "\n",
    "        # Within 1 std\n",
    "       # normalized_1_std = max(min(self.normalized, 1), -1)# for x in self.normalized\n",
    "\n",
    "        # for list\n",
    "        #return (x - self.mean) / self.std for x in X\n",
    "       # print(max(min(self.normalized, 1), -1))\n",
    "       # return normalized_1_std\n",
    "\n",
    "    def apply(self, X):\n",
    "        \"\"\"apply the normalization by the standard deviation to data X using parameters \n",
    "        of the transformation stored in the object\n",
    "        \"\"\"\n",
    "        # for list\n",
    "        #return (x - self.mean) / self.std for x in X\n",
    "        #self.normalized_data = (X - self.mean) / self.std\n",
    "\n",
    "        # Normalize\n",
    "        self.normalized = X - self.mean\n",
    "\n",
    "        # In case standard deviation is 0\n",
    "        self.std[self.std == 1] = 0\n",
    "\n",
    "        # Scale within one standard deviation\n",
    "        self.normalized = self.normalized / self.std\n",
    "\n",
    "        # Normalize by substracting mean and deviding by standard deviation\n",
    "        #self.normalized = (X - self.mean) / self.std\n",
    "        return self.normalized\n",
    "\n",
    "\n",
    "                                \n",
    "    def apply2(self, X):\n",
    "        \"\"\"apply the normalization by the standard deviation to data X using parameters \n",
    "        of the transformation stored in the object\n",
    "        \"\"\"\n",
    "        # for list\n",
    "        #return (x - self.mean) / self.std for x in X\n",
    "        self.normalized_data = (X - self.mean) / self.std\n",
    "        return self.normalized_data\n",
    "\n",
    "        # Within 1 std\n",
    "        #normalized_1_std = max(min(self.normalized, 1), -1)# for x in self.normalized\n",
    "\n",
    "        # for list\n",
    "        #return (x - self.mean) / self.std for x in X\n",
    "        #return normalized_1_std\n",
    "        # Transform the data by subtracting the mean and dividing by the standard deviation\n",
    "        #X_normalized = [[(X[i][j] - self.mean[j]) / self.std[j] for j in range(num_cols)] for i in range(num_rows)]\n",
    "        #return np.array([[(X[i][j] - self.mean[j]) / self.std[j] for j in range(num_cols)] for i in range(num_rows)])\n",
    "                        \n",
    "    def inverse(self, X):\n",
    "        \"\"\"apply the inverse transformation of the normalization by the standard deviation to data X \n",
    "        using parameters of the transformation stored in the object\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        # [(x * original_std_dev) + original_mean for x in normalized_data]\n",
    "        # for list\n",
    "        #return [(x * self.std) + self.mean for x in X]\n",
    "        inverse_data = (X * self.std) + self.mean\n",
    "        return inverse_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "4dc0287fe80848148a6e3b846b1055ea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 125,
    "execution_start": 1696968339274,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22474487 1.22474487]\n",
      "\n",
      "\n",
      "[1.22474487 1.22474487] 1\n",
      "[[ 1.20e-01  2.00e+00]\n",
      " [ 3.00e+00  5.00e+00]\n",
      " [-1.23e+02  7.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.12, 2], [3, 5], [-123, 7]])\n",
    "#print(X)\n",
    "sdn = SdNormalizer()\n",
    "X_norm = sdn.fit_transform(X)\n",
    "#print(X_norm)\n",
    "print(X_norm.std(ddof=1, axis=0))\n",
    "print(\"\\n\")\n",
    "print(X_norm.std(ddof=1, axis=0), 1)\n",
    "#assert(np.allclose(X_norm.std(ddof=1, axis=0), 1))\n",
    "\n",
    "print(sdn.inverse(X_norm))\n",
    "assert(np.allclose(sdn.inverse(X_norm), X))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "0006665f8d414834aac37daea9419be0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 308,
    "execution_start": 1696968367241,
    "source_hash": null,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.         -1.22474487]\n",
      " [ 0.          0.          0.        ]\n",
      " [ 0.          0.          1.22474487]]\n",
      "False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack((np.ones((3,1)), 3*np.ones((3,1)),np.arange(3).reshape((3,1))))\n",
    "#print(X)\n",
    "sdn = SdNormalizer()\n",
    "X_norm = sdn.fit_transform(X)\n",
    "print(X_norm)\n",
    "\n",
    "print(np.allclose(X_norm.std(ddof=1, axis=0), np.array([0, 0, 1])))\n",
    "#assert(np.allclose(X_norm.std(ddof=1, axis=0), np.array([0, 0, 1])))\n",
    "print(\"\\n\")\n",
    "#print(X_norm.std(ddof=1, axis=0), np.array([0, 0, 1]))\n",
    "\n",
    "#print(sdn.inverse(X_norm))\n",
    "\n",
    "#assert(np.allclose(sdn.inverse(X_norm), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "862deb55aa504920905f657b23247ae5",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Sigmoid normalization\n",
    "\n",
    "The sigmoid function (or logistic function) is the real function\n",
    "$$\\sigma(x,\\lambda)=\\frac{1}{1+e^{-\\lambda x}},$$ where the real constant $\\lambda$ is called *slope*.\n",
    "The domain of sigmoid is $(-\\infty,+\\infty)$ and its range is  $(0,1)$.\n",
    "\n",
    "We can plot the sigmoid function for $\\lambda=1$, e.g., in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "47e7e6a8839b49b4a4524438107d016d",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sigmoid function with slope 1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-10,10,0.2)\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "plt.plot(x,y)\n",
    "plt.title('Sigmoid function with slope 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a11aec2ddcad4bb7bcd29a17515b9655",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Implement the methods of the following class `SigmNormalizer` that should implement sigmoid normalization. Its method `fit_transform(X)` transforms two-dimensional array `X` non-linearly using function $\\sigma(x,\\lambda)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "6b471d2a67d44d77be174f314dada90f",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SigmNormalizer(Normalizer):\n",
    "    \"\"\"A class for sigmoid normalization\"\"\"\n",
    "    \n",
    "    def __init__(self, lamda=1):\n",
    "        \"\"\"constructor for sigmoid normalizer\"\"\"\n",
    "        # Lamda to control behavior of the sigmoid function\n",
    "        self.lamda = lamda\n",
    "            \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit SigmNormalizer to data X;\n",
    "        the method returns transformed data.\n",
    "        \"\"\"  \n",
    "        # your code goes here\n",
    "        self.normalized = 1 / (1 + np.exp(-self.lamda * X))\n",
    "        return self.normalized\n",
    "                                \n",
    "    def apply(self, X): #the other way around fit_transform and apply\n",
    "        \"\"\"Apply normalization by the standard deviation to data X using parameters \n",
    "        of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "       # your code goes here\n",
    "        return self.normalized\n",
    "                        \n",
    "    def inverse(self, X):\n",
    "        \"\"\"Apply the inverse transformation of normalization by the standard deviation to data X \n",
    "        using parameters of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        return np.log(X / (1 - X)) / self.lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "6b471d2a67d44d77be174f314dada90f",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SigmNormalizer(Normalizer):\n",
    "    \"\"\"A class for sigmoid normalization\"\"\"\n",
    "    \n",
    "    def __init__(self, lamda=1):\n",
    "        \"\"\"constructor for sigmoid normalizer\"\"\"\n",
    "        self.lamda = lamda\n",
    "            \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit SigmNormalizer to data X;\n",
    "        the method returns transformed data.\n",
    "        \"\"\"  \n",
    "        return self.apply(X)\n",
    "                                \n",
    "    def apply(self, X):\n",
    "        \"\"\"Apply normalization by the standard deviation to data X using parameters \n",
    "        of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        # your code goes here\n",
    "        cs = []\n",
    "        for i in range(X.shape[1]):\n",
    "            c = 1 / (1 + np.exp(-X[:,i] * self.lamda))\n",
    "            cs.append([c])\n",
    "        return np.concatenate(cs, axis=0).T\n",
    "                        \n",
    "    def inverse(self, X):\n",
    "        \"\"\"Apply the inverse transformation of normalization by the standard deviation to data X \n",
    "        using parameters of the transformation stored in the object.\n",
    "        \"\"\"\n",
    "        cs = []\n",
    "        for i in range(X.shape[1]):\n",
    "            c = np.log(1 / X[:,i] - 1) / - self.lamda\n",
    "            cs.append([c])\n",
    "        return np.concatenate(cs, axis=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cell_id": "54b517ed592a4616819191819e1353dc",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.59713649e-001 9.82013790e-001]\n",
      " [9.97527377e-001 9.99954602e-001]\n",
      " [1.45732848e-107 9.99999168e-001]]\n",
      "\n",
      "\n",
      "[[ 1.20e-01  2.00e+00]\n",
      " [ 3.00e+00  5.00e+00]\n",
      " [-1.23e+02  7.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.12, 2], [3, 5], [-123, 7]])\n",
    "#print(X)\n",
    "sigmn = SigmNormalizer(lamda=2)\n",
    "X_norm = sigmn.fit_transform(X)\n",
    "print(X_norm)\n",
    "print(\"\\n\")\n",
    "#print(np.allclose(X_norm, np.array([[0.559713649, 0.982013790], [0.997527377, 0.999954602], [0, 0.999999168]])))\n",
    "assert(np.allclose(X_norm, np.array([[0.559713649, 0.982013790], [0.997527377, 0.999954602], [0, 0.999999168]])))\n",
    "print(sigmn.inverse(X_norm))\n",
    "assert(np.allclose(sigmn.inverse(X_norm), X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "d6db8ea96f3c499b8875e10a2b17567e",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 3. 0.]\n",
      " [1. 3. 1.]\n",
      " [1. 3. 2.]]\n",
      "[[0.73105858 0.95257413 0.5       ]\n",
      " [0.73105858 0.95257413 0.73105858]\n",
      " [0.73105858 0.95257413 0.88079708]]\n",
      "[[1. 3. 0.]\n",
      " [1. 3. 1.]\n",
      " [1. 3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack((np.ones((3,1)), 3*np.ones((3,1)),np.arange(3).reshape((3,1))))\n",
    "print(X)\n",
    "sigmn = SigmNormalizer()\n",
    "X_norm = sigmn.fit_transform(X)\n",
    "print(X_norm)\n",
    "assert(np.allclose(X_norm, np.array([[0.73105858, 0.95257413, 0.5],\n",
    "                                     [0.73105858, 0.95257413, 0.73105858],\n",
    "                                     [0.73105858, 0.95257413, 0.88079708]])))\n",
    "print(sigmn.inverse(X_norm))\n",
    "assert(np.allclose(sigmn.inverse(X_norm), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "986f7053066240f88e89409381c74c45",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "Are there functions implementing the above normalization method in `numpy` or `scikit-learn` libraries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "6362909df0d249919b342020ced8c1f2",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cabac8b3f96e44878d623fe5ce892aca",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=4c50f001-e560-454a-8045-3a629ed0f10e' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ce6d36b75f7c42eab4964e901e0c4d19",
  "deepnote_persisted_session": {
   "createdAt": "2023-10-10T15:45:21.637Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
